# Unicode. Основные принципы. Сравнение UTF-8 и UTF-16.

## История создания и основные принципы.

Стандарт кодирования символов Unicode (Юникод) был предложен в 1991 году некоммерческой организацией "Консорциум Юникода". Он содержит практически любой символ, который можно представить, включая непечатаемые. До его появления использовались в основном однобайтные кодировки, которые имели ряд недостатков:

- Шрифты были привязаны к конкретной кодировке;

- Одновременно можно было работать только с 256 символами, 128 из которых были зарезервированы под управляющие и латинские символы, а для остальных кроме нужного алфавита необходимо было найти место для символов псевдографики - ╔ ╗;

- Любая кодировка представляла определенный набор символов и при конвертации возможны были потери, когда отсутствующие символы заменялись на графически похожие;

- Перенос файлов между компьютерами с разными операционными системами был весьма проблематичен. Необходимо было либо конвертировать их, либо переносить вместе с файлом дополнительные шрифты;

- Существуют неалфавитные письменности (иероглифические, такие как китайская, японская и т.п.), которые невозможно представить в однобайтной кодировке.

Для примера, кодировка ASCII содержит 128 символов (кодовых точек):

- От 0 до 31 – контрольные и неотображаемые символы, такие как NUL, STX, BEL и т.д.;
- от 32 до 64 – знаки пунктуации, символы, числа и пробел;
- от 65 до 90 – буквы английского алфавита в верхнем регистре;
- от 91 до 96 – дополнительные графемы, такие как "[" и "\";
- от 97 до 122 – буквы английского алфавита в нижнем регистре;
- от 123 до 126 – дополнительные графемы, такие как "{" и "|";
- 127 – контрольный неотображаемый символ DEL.

Если какого-то символа нет в этой кодировке, значит вывести его с помощью ASCII не получится. В Юникоде содержится 1 114 112 или 0x10ffff (в шестнадцатеричном представлении) возможных кодовых точек. На момент написания статьи в актуальной версии стандарта 13.0.0 содержится 143 859 символов, разделенных на 154 сценария, то есть не задействована даже половина из доступных точек.

Стандарт Юникода включает в себя множество алгоритмов обработки текстовых данных. Единого дизайна для всех возможных процессов и алгоритмов не существует, поэтому Юникод старается найти баланс между разными требованиями со стороны использующих его программ.

Юникод отражает 10 фундаментальных принципов:

#### 1.    Универсальность

В стандарте закодирован единый, очень большой набор символов (Universal character set, UCS), охватывая все символы, требующиеся для всемирного использования. Их хватает для текстового представления всех современных письменностей и для исторических систем письма.

В наборе символов представлено большое количество семантических данных, с помощью которых можно производить сложные операции по обработке текста.

#### 2.    Эффективность

Стандарт разрабатывается так, чтобы сделать возможным эффективную реализацию алгоритмов. Отсутствуют экранированные последовательности, состояния и т.д. Каждый символ имеет тот же статус, что и любой другой. Все коды одинаково доступны.

Все формы кодирования само-синхронизируются и не перекрываются. Поэтому случайный доступ и поиск внутри потока символов эффективен.

Символы конкретных письменностей группируются вместе настолько, насколько это возможно. Это позволяет делать алгоритмы более компактными и реализовывать более эффективные методы сжатия.

Общие знаки препинания кодируются едиными символами. Символы форматирования имеют конкретные и однозначные функции.

#### 3.    Символы, а не глифы

Юникод различает символы и глифы. 

Символы – абстрактное представление компонентов письменности, которые имеют семантическое значение. В основном это буквы, знаки препинания и другие символы, составляющие текст. Символы указываются с помощью кодовых точек, которые хранятся в виде строк в памяти или на диске. Юникод оперирует только кодовыми точками.

Глифы представляют визуальную форму. Они указывают, как символы должны отображаться на экране монитора или на бумаге. Любой шрифт представляет собой набор глифов. Глифы не являются частью Юникода.

Это объясняется тем, что отдельный глиф может соответствовать одному символу или нескольким. И наоборот, несколько символов могут отображаться с помощью одного глифа.

То, что определяется пользователем одним символом (независимо от того, представлен он одним глифом или несколькими), может быть представлено в Юникоде, как одна или несколько кодовых точек.

#### 4.    Семантика

Стандарт предоставляет для символов четко определенную семантику. Она описывается через свойства символов, а не через их имена или позицию в таблицах кодов.

База данных Юникода (UCD) предоставляет машиночитаемые таблицы свойств символов для использования в реализации синтаксического анализа, сортировки и других алгоритмов, требующих семантических сведений о кодовых точках.

В стандарте определено более 100 различных свойств, включая числовые, регистр, комбинацию и свойства направленности. При необходимости могут определятся дополнительные свойства.

Если символы используются по-разному в разных языках, соответствующие свойства определяются за рамками стандарта.

 Юникод предполагает, что символы и их свойства неразрывно связаны между собой. Если интернациональное приложение может быть структурировано для работы непосредственно с использованием символов Юникода, все уровни реализации могут надежно и эффективно обращаться к хранилищу символов и быть уверенными в универсальной применимости семантики свойств символов.

#### 5.    Простой текст

Простой текст (Plain text) – это простая последовательность кодов символов. Таким образом, простой текст в кодировке Юникод представляет собой последовательность кодов символов Юникод. В отличие от него, стилизованный (форматированный) текст содержит также дополнительную информацию, такую как идентификатор языка, размер шрифта, цвет, гипертекстовые ссылки и т.д.

Относительные функциональные роли как простого текста, так и стилизованного представлены ниже:

- Простой текст – это основной поток контента, к которому может применяться форматирование;
- Форматированный текст содержит сложную информацию о форматировании, а также текстовый контекст;
- Простой текст является общедоступным, стандартизированным и универсальным для чтения;
- Стилизованный текст зависит от использующей его реализации.

Так как форматированный текст содержит простой текст и дополнительную информацию, чтобы показать «чистый» текст дополнительную информацию всегда можно убрать. Эта операция часто используется в системах обработки текста, которые используют как свой собственный частный формат, так и формат обычного текстового файла в качестве универсального.

Простой текст представляет только содержимое символа, а не его внешний вид. При использовании различных алгоритмов визуализации, один и тот же простой текст может иметь разный внешний вид. Из взаимосвязи между внешним видом и содержанием простого текста можно вывести основное правило:

Простой текст должен содержать достаточно информации, чтобы текст был разборчивым, и не более того.

Юникод кодирует простой текст. Различие между обычным текстом и другими формами данных в одном потоке данных является функцией протокола более высокого уровня и не определяется стандартом Юникода.

#### 6.    Логический порядок

Логический порядок – это порядок, в котором текст в кодировке Юникод хранится в памяти. Он схож с порядком ввода текста с клавиатуры и примерно соответствует фонетическому порядку. Для десятичных чисел логический порядок значит, что наиболее значимая цифра идет первой.

При отображении логический порядок часто соответствует линейному выводу символов в одном направлении. Например, слева направо, справа налево или сверху вниз. В других случаях порядок хранения текста в памяти и порядок вывода отличаются. Например, когда алфавит с направлением письма справа налево (арабский или иврит) смешивается с письмом слева направо (латинский или кириллица). 

Стандарт Юникод точно определяет преобразование текста из логического порядка в порядок читаемого текста. Свойства направленности, присущие символам, обычно определяют правильный порядок отображения текста. Двунаправленный алгоритм Юникода указывает, как эти свойства используются для разрешения направленных взаимодействий, когда символы направленности справа налево и слева направо смешиваются.

Помимо смешивания теста с различным направлением, есть много других случаев, когда логический порядок не соответствует линейной последовательности символов. Есть одно конкретное исключение из обычной практики логического порядка, параллельного фонетическому. В сценариях тайского, лаосского, тайвьетского и нового тайлуэ пользователи традиционно вводят текст в визуальном порядке, а не в фонетическом. В результате чего некоторые гласные буквы сохраняются перед согласными, да если они произносятся после них.

#### 7.    Унификация

Юникод позволяет избежать дублирования кодирования символов, объединяя их в группы по письменностям. Общим буквам присваивается один код, независимо от языка, также, как и обычным китайским/японским/корейским идеограммам (CJK). Знаки препинания, символы и диакритические знаки обрабатываются аналогично буквам.

В некоторых языках одинаковые символы могут использоваться по-разному. Например, запятая «,» в английском языке служит для разделения тысяч, а во французском для отделения дробной части. Юникод избегает дублирования символов из-за специфического использования на разных языках. Дублирование происходит только для поддержания совместимости с уже существующими стандартами.

Существует несколько случаев, когда визуально похожие буквы кодируются разными символами. Например, латинская «о», кириллическая «о» и греческая «о» (омикрон). Они не унифицированы, потому что принадлежат разным языкам и многие устаревшие кодировки различают их. В качестве другого примера, есть 3 буквы D, одинаково выглядящих в верхнем регистре, но по-разному в нижнем регистре. Если кодировать прописные разными кодами, а заглавные одним, это приведет к проблемам при изменении регистра.

Многие символы в Юникоде могли быть объединены с существующими визуально похожими символами или могли быть опущены в пользу какого-либо другого механизма Юникода для поддержания типов тестовых различий, для которых они были предназначены. Однако соображения совместимости с другими стандартами и системами часто требуют, чтобы такие символы совместимости были включены в стандарт Юникод.

#### 8.    Динамическая композиция

Юникод позволяет динамически комбинировать акцентированные формы (знаки с диакритикой) и слоги корейского письма Хангыль. Для этого используются композиции базовых и комбинированных символов. Например, диэрезис «¨» может использоваться со всеми гласными и рядом согласных в языках, использующих латинский шрифт.

##### Эквивалентные последовательности

Некоторые текстовые элементы могут быть закодированы как предварительно составленные статические формы или посредством динамической композиции. Например, символ U+00DC или «Ü» - это статическая форма, записываемая одним символом. Или можно было записать её, используя латинскую букву U и комбинируемый диэрезис. Для статических предварительно составленных форм Юникод обеспечивает сопоставление с эквивалентной динамически составленной последовательностью символов.

То есть, различные последовательности символов Юникод считаются эквивалентными. Предварительно составленный символ может быть представлен эквивалентной составной последовательностью символов.

#### 9.    Стабильность

Некоторые аспекты Юникода должны оставаться абсолютно стабильными от версии к версии, чтобы разработчики и пользователи могли быть уверены, что текст даже после кодирования сохранит то же значение. Это значит, что после определения символа в Юникоде, он не может быть удален или присвоен другой кодовой точке. 

Символы, определенные в стандарте, остаются навсегда, но некоторые могут быть признаны устаревшими и их использование в новых документах категорически не рекомендуется. В то же время реализации должны продолжать распознавать такие символы. Когда они встречаются, средства проверки орфографии или редакторы могут предупреждать об их присутствии и предлагать адекватную замену. Имена символов также никогда не меняются, поэтому из можно использовать как идентификаторы, действительные для разных версий.

Такая же стабильность существует для некоторых важных свойств. Например, декомпозиции сохраняются стабильными, поэтому можно единожды нормализовать текст в Юникоде и сохранить его для всех будущих версий.

#### 10.  Совместимость

Юникод сохраняет идентичность символов для совместимости с большим количеством различных базовых стандартов, включая национальные, международные и стандарты поставщиков. Если разные формы (или одна и та же) одного символа представлены в базовом стандарте разными кодами, Юникод также сохранит разделение для поддержания совместимости. Это помогает просто отобрать символы между Юникодом и базовым стандартом.

Для стандартов, широко используемых с мая 1993 года, гарантируется точная конвертируемость со стандартом Юникод. Также учитываются важные изменения в этих стандартах, сделанные позже.

Обычно, одна кодовая точка из другого стандарта соответствует одной кодовой точке в Юникоде. Но, бывает, что одной кодовой точке из другого стандарта соответствует последовательность кодовых точек в Юникоде, или наоборот. Точно заданное соответствие между символами Юникода и других кодировок упрощает конвертацию.

## Сравнение UTF-8 и UTF-16

UTF расшифровывается как Unicode Transformation Format (формат преобразования Юникод). Это семейство стандартов для кодирования наборов символов Юникод в его эквивалентное двоичное значение. UTF был разработан таким образом, чтобы пользователи имели стандартизированные средства кодирования символов с минимальным количеством места.

Стандарт Юникода включает описание ряда кодировок, например, UTF-8 и UTF-16BE/UTF-16LE. Они отличаются только тем, сколько байтов используется для кодирования каждого символа. Так как оба стандарта являются кодированием с переменной шириной, они могут использовать до 4 байтов при кодировании данных. Однако, когда дело доходит до минимума, UTF-8 использует только 1 байт (8-битное кодирование), а UTF-16 использует 2 байта (16-битное кодирование).

UTF-8 – это представление Юникода в 8-битном виде. Он обеспечивает наилучшую совместимость со старыми системами, использовавшими 8-битные символы, благодаря обратной совместимости с ASCII. При кодировании файла, который использует только символы ASCII с UTF-8, результирующий файл будет идентичен файлу, закодированному с ASCII. При использовании UTF-16 это невозможно, так как каждый символ будет иметь длину 2 байта. Это относится ко всем европейским языкам.

UTF-8 является единственной кодировкой для XML данных, которая не требует наличия маркера последовательности байтов или индикации метода кодировки.

Например, если пересылать по сети HTML-страницу с кириллическим текстом, то UTF-8 оказывается наиболее выгодным, так как вся разметка, а также JavaScript и CSS блоки будут кодироваться одним байтом. UTF-16 займет в 2 раза больше места.

Различие UTF-16BE (<u>B</u>ig <u>E</u>ndian) и UTF-16LE (<u>L</u>ittle <u>E</u>ndian) заключается в маркировке последовательности байтов (определяется меткой порядка байтов – Byte order mark). Для этого в Юникоде зарезервировано 2 кодовых точки, U+FEFF для Big Endian и U+FFFE для Little Endian. Если порядок байтов указан извне, то есть кодировка описана как UTF-16BE или UTF-16LE, тогда метка порядка байтов в тексте не нужна.

Устаревшее программное обеспечение, не поддерживающее Юникод, не сможет открыть файл с кодировкой UTF-16, даже если в нем только символы ASCII.

UTF-8 является байтовым форматом и поэтому не имеет проблем с байтовыми сетями или файлами. Также он лучше работает с поврежденными файлами или потоками, так как может декодировать следующий исправный байт. UTF-16, с другой стороны, должен устанавливать порядок байтов для работы с такими сетями и файлами. При работе с поврежденными фалами он ведет себя аналогично UTF-8, если некоторые байты повреждены. Однако, часть байтов может теряться, и потерянный элемент может смешать следующие комбинации байтов. В итоге, конечный результат будет искажен.

Для хранения строковой информации в приложениях часто используется UTF-16, так как они довольно просты, и символы основных мировых систем письма кодируются одним 16-битным символом. Например, Java для внутреннего представления строк применяет UTF-16. Операционная система Windows внутри себя также использует UTF-16.

При кодировании текста, представленного иероглифической письменностью, UTF-16 будет выгоднее, так как в UTF-8 будет использовано по 3 байта на символ. Для примера можно рассмотреть китайский иероглиф «語». Кодировка в UTF-8:

`11101000 10101010 10011110`

Кодировка в UTF-16 получается короче:

`10001010 10011110` 

UTF-16 обычно лучше подходит для представления в памяти, так как порядок последовательности байтов здесь не имеет значения (можно использовать собственный порядок), а индексация выполняется быстрее (при условии, что разработчик знает и умеет правильно обращаться с суррогатными парами). UTF-8 в свою очередь очень хорош для текстовых файлов и сетевых протоколов, так как нет проблем с последовательностью байтов, часто полезно нулевое завершение, а также совместимость с ASCII.
